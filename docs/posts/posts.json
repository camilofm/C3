[
  {
    "path": "posts/umbrella_pipeline/",
    "title": "Pipeline QM/MM para Umbrella Sampling: completamente automatizado",
    "description": "Mostramos un pipeline real para procesar ventanas Umbrella Sampling (n/p), desde RMSD y solapamiento hasta WHAM y PMF, usando QMMM PM6/CHARMM.",
    "author": [
      {
        "name": "Dr. Camilo Febres-Molina",
        "url": "https://github.com/camilofm"
      }
    ],
    "date": "2025-11-28",
    "categories": [],
    "contents": "\nIntroducción\nEn muchos trabajos de dinámica molecular híbrida QM/MM, calcular un\nperfil de energía libre (PMF) a partir de Umbrella Sampling es un\nproceso largo, repetitivo y propenso a errores manuales:\ncopiar cientos de archivos del clúster,\ncalcular RMSD de proteína, donor y acceptor,\nrevisar solapamiento entre ventanas,\ngenerar metadata,\ncorrer WHAM,\nlimpiar extremos,\nsuavizar el perfil,\nexportar imágenes.\nTodo eso, a mano, consume horas.\nEn este post presento un pipeline completamente automatizado que\ndesarrollé para procesar las ventanas del sistema\nQM/MM (PM6/CHARMM) en mi proyecto actual.\nUna vez que tengo las ventanas *.rc y *_eq.dcd en una carpeta,\nel pipeline tarda ≈ 11 segundos en entregar:\nRMSD global, Donor y Acceptor (PNG)\nSolapamiento de ventanas (PNG)\nPMF original WHAM (PNG)\nPMF limpio + spline (PNG)\nArchivos CSV procesados\nHTML con diagnósticos\nTodo ordenado automáticamente en una carpeta resultados/.\nEl pipeline: visión general\nEl flujo completo está diseñado para ejecutarse con un solo comando:\nbash run_pipeline.sh\nEste script llama secuencialmente a:\nrmsd_windows.tcl — RMSD de PROA, DON, ACC\nrmsd_us_mep-rca.Rmd — análisis y PNG\nus_rc_overlap_np.Rmd — solapamiento (PNG)\ngen_metadata.sh — metadata para WHAM\nwham_rca_v6.py — WHAM + PMF original\npmf_wham_final.Rmd — PMF limpio + spline\nCopia automática de PNG → carpeta resultados/\nTodas estas etapas están registradas en pipeline.log.\nArquitectura del script maestro\nA continuación un extracto simplificado del script run_pipeline.sh:\nrun_step \"3. Generar solapamiento de RC\" \\\n  env RSTUDIO_PANDOC=\"$PANDOC_BIN\" \\\n  Rscript -e \"rmarkdown::render('us_rc_overlap_np.Rmd', quiet = TRUE)\"\n\nrun_step \"7. Copiar imágenes finales\" \\\n  bash copy_outputs.sh\nEl diseño modular permite ajustar fácilmente cualquier etapa sin romper\nlas otras.\nResultados producidos automáticamente\nLos archivos finales que produce el pipeline incluyen:\n✔️ RMSD\nrmsd_prot_all.png\nrmsd_don_all.png\nrmsd_acc_all.png\n✔️ Solapamiento de las ventanas\nus_overlap_density.png\n✔️ PMF WHAM (crudo y limpio)\npmf_wham_original.png\npmf_wham_clean.png\nTodos se copian a:\nresultados/\n¿Por qué este pipeline es valioso?\nAhorra horas de trabajo repetitivo.\nElimina errores humanos en el copiado/pegado.\nEstándar reproducible para futuros artículos o estudiantes.\nTotalmente portable entre proyectos (solo cambiar nombres PSF/DCD).\nProduce figuras listas para un manuscrito.\nEste pipeline nació como herramienta interna, pero se ha convertido en\nparte fundamental de mi flujo de trabajo QM/MM para enzimas.\nArchivos y repositorio\nSi te interesa ver el pipeline completo, todos los scripts interoperan:\nBash (control maestro)\nTCL (VMD)\nPython (WHAM)\nRMarkdown (figuras)\nLo incluiré próximimamente en mi GitHub como un ejemplo reproducible.\n\n\n\n",
    "preview": {},
    "last_modified": "2025-11-28T16:03:32-03:00",
    "input_file": "umbrella_pipeline_blog.knit.md"
  },
  {
    "path": "posts/qmmm/",
    "title": "QM/MM: La Fusión de lo Cuántico y Molecular",
    "description": "Descubre cómo la combinación de Mecánica Cuántica y Molecular permite estudiar reacciones químicas complejas, como las que ocurren en enzimas, logrando una precisión a nivel cuántico que antes era inalcanzable en sistemas de gran tamaño.",
    "author": [
      {
        "name": "Dr. Camilo Febres-Molina",
        "url": "https://github.com/camilofm"
      }
    ],
    "date": "2024-11-24",
    "categories": [],
    "contents": "\n\n\n\nPerspectiva General\nEn el campo de la Química Computacional, vamos a hablar sobre un tema fascinante: los cálculos QM/MM (Quantum Mechanics/Molecular Mechanics). Esta técnica híbrida combina métodos mecano-cuánticos y mecánica molecular, lo que permite estudiar sistemas grandes de manera eficiente.\nA lo largo de este post, utilizaremos como ejemplo una proteína con un ligando cualesquiera, pero ten en cuenta que también es posible realizar cálculos QM/MM en diversas moléculas para distintas aplicaciones, como materiales orgánicos, complejos metálicos, fármacos y muchos tipos de sistemas catalíticos. Además, mencionaré brevemente el uso de Teoría del Funcional de la Densidad (DFT), una metodología común en los cálculos QM que se utiliza para describir con precisión la densidad electrónica de los sistemas.\nEn este post, te guiaré desde el principio para que puedas comprender los conceptos básicos y cómo funciona esta metodología en general. Además, por medio de un ejemplo ilustraré los pasos fundamentales de esta poderosa herramienta que te será de utilidad incluso si estás empezando en el mundo de la química computacional.\n¡Espero que disfrutes este viaje hacia la comprensión de una de las técnicas más útiles y emocionantes en el estudio de biomoléculas!\nComencemos con lo fundamental: ¿Qué es QM/MM?\nEl enfoque QM/MM combina dos metodologías, Mecánica Cuántica (QM) y Mecánica Molecular (MM), ambas de gran importancia para entender la dinámica de sistemas complejos:\nMecánica Cuántica (QM): Se utiliza para modelar una parte del sistema donde los efectos cuánticos son importantes, como en la reacción química de un sitio activo de una enzima. Aquí, se consideran explícitamente las rupturas y formaciones de enlaces químicos, lo cual es esencial para describir reacciones químicas de manera precisa. Por ejemplo, en una enzima, los enlaces del sustrato pueden romperse o formarse durante la reacción, y estos cambios solo pueden describirse con precisión utilizando la mecánica cuántica, ya que implican la redistribución de densidad electrónica (la distribución de los electrones en el espacio) y la creación de nuevos estados electrónicos (como la formación de nuevos enlaces). En este contexto, la Teoría del Funcional de la Densidad (DFT) es una técnica ampliamente utilizada que permite describir la densidad electrónica de manera eficiente y con un buen equilibrio entre precisión y costo computacional.\nMecánica Molecular (MM): Debido al costo computacional elevado en el cálculo QM, se usa la mecánica molecular para el resto del sistema, que generalmente incluye una gran cantidad de átomos (como un solvente o el resto de la proteína), de manera menos costosa computacionalmente. La mecánica molecular se encarga de modelar las interacciones de corto y largo alcance de estos átomos mediante potenciales clásicos. Las interacciones de corto alcance incluyen fuerzas como las repulsivas y atractivas de Van der Waals, mientras que las de largo alcance comprenden interacciones electrostáticas. Para tratar estas interacciones de largo alcance de manera eficiente, se utilizan algoritmos como el PME (Particle Mesh Ewald), que permite calcular las fuerzas electrostáticas con alta precisión, incluso para sistemas muy grandes.\nEn el contexto de la química computacional, este enfoque permite reducir los requisitos de recursos al tiempo que mantiene la precisión para estudiar la parte más relevante del sistema.\n¿Cómo se realiza un cálculo QM/MM?\nPara realizar un cálculo QM/MM, es necesario utilizar un software especializado que permita combinar ambos enfoques, el cuántico y el molecular. Generalmente, se elige un software que se adapte bien a la naturaleza del sistema y que sea compatible con los métodos híbridos. Para comprender mejor el procedimiento, y como mencioné al inicio, colocaré un ejemplo de cálculo y metodología para el análisis de una proteína y un ligando utilizando la interfaz Qchem-CHARMM, que permite realizar cálculos QM/MM de manera eficiente. Qchem se encarga de la parte cuántica, donde se modelan las reacciones y los procesos que involucran cambios en los enlaces químicos, mientras que CHARMM se encarga de la parte molecular, proporcionando el contexto completo de la proteína o del sistema en su totalidad.\nPrimero, se debe definir qué parte del sistema será tratada con QM (generalmente el sitio activo o la región de interés donde ocurre una reacción) y qué parte se tratará con MM (el resto del sistema, como la proteína y el solvente). Luego, se configura la simulación con los parámetros adecuados para cada método, y se ejecuta la simulación utilizando la interfaz Qchem-CHARMM para integrar ambas partes del cálculo.\nPara ilustrar mejor esta combinación de ambas zonas, a continuación se muestra la imagen de un sistema proteico y su ligando, resaltando la región QM (el sitio activo), mientras que el resto del sistema es tratado con MM indicando su contribución al cálculo. Esto ayudará a visualizar cómo se dividen las regiones y cuál es el enfoque general de cada una.\nDebido a la gran diversidad de sistemas, enzimas y reacciones, no existe una ‘receta general’ para los cálculos QM/MM. En este post, a modo de ejemplo, se presentará una forma de proceder, que es la que, personalmente yo, utilizo habitualmente en mis investigaciones.\nÉsta incluye los siguientes pasos: optimizaciones geométricas, exploración de la energía potencial, búsqueda del camino de mínima energía, análisis de los resultados, y análisis de la energía y la estructura.\nPasos Generales\nOptimización geométrica: Se realiza una optimización de la estructura utilizando primero solo MM y luego una combinación QM/MM para ajustar las regiones de interés con precisión cuántica.\nExploración de coordenada de reacción: Se lleva a cabo un “scan”, que consiste en optimizaciones geométricas a lo largo de una coordenada de reacción (RC). Esta coordenada de reacción se define mediante una combinación de distancias entre átomos y permite mapear cómo cambia la energía a medida que ocurre la reacción.\nBúsqueda del camino de mínima energía: Una vez que se obtiene la trayectoria inicial a lo largo de la coordenada de reacción, se utiliza el algoritmo CPR (Conjugate Peak Refinement) implementado en el módulo TREK del software CHARMM para encontrar el camino de mínima energía. Este proceso permite identificar un camino adiabático de mínima energía (es decir, un camino en el que no se intercambia calor con el entorno) que conecte reactantes con productos. Así como también, el CPR logra identificar uno o más estados de transición (TS) verdaderos.\nCálculo de energía puntual (single point energy): Seguidamente, se realiza un cálculo de energía puntual (single point energy) en los tres estados principales de la reacción: el reactante, el estado de transición (TS), y el producto. Esto se hace con un nivel de teoría mucho mejor (un modelo más preciso para describir el sistema cuántico) para recalcular las energías en estos tres puntos y mejorar los resultados de la barrera de energía asociada a la reacción.\nAnálisis de los resultados: Se realiza un análisis general de los resultados obtenidos. Esto incluye:\nAnálisis estructural o geométrico: Se examinan las estructuras optimizadas de los puntos estacionarios (reactante, estado de transición y producto) para identificar cambios importantes en las geometrías a lo largo de la reacción.\n\n\nGráfico que muestra los tres puntos estacionarios de la reacción por la que pasa el camino de mínima energía: el reactivo (R), el estado de transición (TS) y el producto (P). [§]\nDiagramas de energía: Se analizan los perfiles de energía para identificar la barrera energética asociada a la reacción y evaluar su viabilidad.\n\nPerfil de energía potencial vs una coordenada de reacción del “scan”. Esta es una aproximación inicial que nos permitirá a continuación encontrar el camino de mínima energía. [§]\n\n\n\n\nCálculo de energía puntual (single point energy, en inglés) de los puntos estacionarios. Se muestra la barrera o energía de activación (8.8 kcal/mol) de la reacción catalizada por la enzima. [§]\nAnálisis NBO (Natural Bond Orbital): Se investigan las cargas de los puntos estacionarios de la reacción para entender la distribución de la carga electrónica y cómo esta influye en la reactividad del sistema.\n\nEstado de transición de la reacción donde se muestran zonas coloreadas que indican las principales interacciones entre los átomos relacionados a la reactividad. [§]\nConclusión:\nEn resumen, el enfoque QM/MM nos permite estudiar sistemas complejos de manera eficiente, combinando la precisión de la mecánica cuántica con la versatilidad y menor costo computacional de la mecánica molecular. A través de los pasos descritos —desde la optimización geométrica hasta el análisis de resultados—, es posible entender en detalle el mecanismo de reacción de biomoléculas y sistemas catalíticos. Los resultados obtenidos, integrando análisis energéticos, NBO y estructurales, nos brindan una visión completa del proceso reactivo, la cual puede ser comparada con otros sistemas similares para validar nuestras conclusiones. Esta poderosa metodología híbrida ha demostrado ser una herramienta fundamental para desentrañar los complejos y diferentes mecanismos catalíticos enzimáticos, proporcionando información clave que puede guiar futuras investigaciones.\n\n\n\nEs importante recalcar que todo lo presentado en este post es solo una de las varias maneras de realizar un cálculo QM/MM, y que los pasos presentados aquí reflejan un ejemplo específico basado en mi experiencia de trabajo.\n\n\n\nNota a pie de página\n[§] Las imagenes colocadas en este post sirven como ejemplos ilustrativos de una de las maneras en las que se puede trabajar con el método QM/MM.\nPara mayor información revisar el artículo publicado en la revista Organic & Biomolecular Chemistry †.\nReferencia\n†Febres-Molina, Camilo; Prat-Resina, Xavier; Jaña, Gonzalo A. 2023. “Resveratrol Glucosylation by GTF-SI from Streptococcus Mutans: Computational Insights into a GH70 Family Enzyme.” Organic & Biomolecular Chemistry 21 (48): 9591–9602.\n\n\n\n",
    "preview": "posts/qmmm/qm-mm_white-bg.png",
    "last_modified": "2024-11-24T02:19:26-03:00",
    "input_file": "qmmm.knit.md"
  },
  {
    "path": "posts/AIM/",
    "title": "La Teoría de Átomos en Moléculas (AIM - en Inglés)",
    "description": "La Teoría de Átomos en Moléculas (AIM) es una herramienta poderosa creada por Richard F. W. Bader en los años 70 y 80. Esta teoría redefine cómo vemos los átomos en una molécula usando la densidad electrónica. Identificando puntos críticos y superficies de cero flujo, AIM desentraña cómo los átomos interactúan dentro de las moléculas, revolucionando nuestra comprensión de la estructura y reactividad química.  \n¡Una joya para la química teórica y computacional!",
    "author": [
      {
        "name": "Camilo Febres-Molina",
        "url": "https://github.com/camilofm"
      }
    ],
    "date": "2024-07-06",
    "categories": [],
    "contents": "\n\n\n\nLa Teoría de Átomos en Moléculas (Atoms In Molecules, AIM - en Inglés)\nOrígenes y Desarrollo\nDurante las décadas de 1970 y 1980, Richard F. W. Bader, un destacado químico cuántico canadiense, desarrolló la revolucionaria teoría de ‘Átomos en Moléculas’ (AIM). Bader, tras completar su licenciatura y maestría en McMaster University, obtuvo su doctorado en el MIT en 1958. Durante su carrera académica en la University of Ottawa y posteriormente en McMaster University, Bader se dedicó a encontrar una forma precisa y rigurosa de definir los átomos dentro de una molécula.\n\n\n\n\nRichard F. W. Bader - septiembre 2009\n\n(CNCC 2009)\nDesarrollo de AIM\nEn su búsqueda de esta definición, Bader observó que la densidad electrónica, ρ(r), podría ser utilizada para delimitar regiones atómicas dentro de una molécula. Esta observación fue el punto de partida para el desarrollo de la teoría AIM, que se basa en el análisis topológico de la densidad electrónica. La teoría establece que los átomos en una molécula se pueden identificar y definir mediante la topología de su densidad electrónica.\nLa Historia de la Teoría AIM\nLos Primeros Años: Definiendo el Átomo\nEn los años 70, Bader y su equipo comenzaron a explorar cómo la densidad electrónica podría utilizarse para definir las regiones atómicas dentro de una molécula. Descubrieron que la topología de la densidad electrónica ofrecía una forma natural de dividir una molécula en átomos.\nConceptos Clave:\nDensidad Electrónica (ρ(r)): La densidad electrónica en un punto r describe la probabilidad de encontrar un electrón en esa posición.\n\\[\n\\rho(\\mathbf{r}) = \\sum_{i=1}^N |\\psi_i(\\mathbf{r})|^2\n\\]\nEsta ecuación muestra la densidad electrónica, donde \\(\\psi_i(\\mathbf{r})\\) son las funciones de onda de los electrones y \\(\\mathbf{r}\\) es el vector posición.\nLa densidad electrónica es importante para definir cómo se distribuyen los electrones alrededor de los núcleos atómicos en una molécula.\nGradiente de Densidad Electrónica (∇ρ(r)): El gradiente de la densidad electrónica, que es la primera derivada parcial de la densidad electrónica, indica la dirección de mayor cambio en la densidad.\n\\[\n\\nabla \\rho(\\mathbf{r}) = \\left( \\frac{\\partial \\rho}{\\partial x}, \\frac{\\partial \\rho}{\\partial y}, \\frac{\\partial \\rho}{\\partial z} \\right)\n\\]\nEl gradiente de densidad electrónica es fundamental para identificar las superficies de interacción atómica, ya que muestra cómo cambia la densidad en diferentes direcciones.\nPrincipios AIM\nBasándose en la topología de la densidad electrónica, la teoría AIM proporciona una manera precisa de identificar y definir los átomos y sus interacciones dentro de una molécula. Esta teoría permite el análisis detallado de la estructura molecular a través de los puntos críticos de la densidad electrónica y las regiones mononucleares (\\(\\Omega\\)).\nPuntos Críticos:\nLos puntos críticos son lugares en el espacio donde el gradiente de la densidad electrónica es cero, es decir, donde no hay cambio en la densidad en ninguna dirección. Esto significa que en estos puntos, la densidad electrónica es extrema (máxima o mínima) o tiene un comportamiento de silla de montar.\nEstos puntos se clasifican según la curvatura de la densidad electrónica en esas posiciones. Los números entre paréntesis (3,-3), (3,-1), (3,+1), (3,+3) se refieren a la naturaleza del punto crítico:\nEl primer número (3) indica el número de dimensiones en las cuales se puede describir la densidad electrónica.\nEl segundo número (-3, -1, +1, +3) describe el tipo de punto crítico, especificando el número de direcciones en las que la densidad electrónica es un máximo (-) o un mínimo (+).\n\nNúcleo (3,-3): Máximos locales de densidad que corresponden a los núcleos de los átomos. Indican la posición del núcleo en el espacio.\nEnlace (3,-1): Puntos de silla que indican la existencia de enlaces químicos. Estos puntos se encuentran entre núcleos de átomos y son indicativos de la presencia de un enlace.\nPlano (3,+1) y Jaula (3,+3): Mínimos locales de densidad que se relacionan con estructuras tridimensionales más complejas dentro de la molécula.\n\nSuperficies de Interacción Atómica:\nLos átomos en una molécula están delimitados por superficies de flujo cero (\\(S(\\Omega)\\)) en el campo vectorial del gradiente de la densidad electrónica, \\(\\nabla \\rho(\\mathbf{r})\\). Estas superficies no son cruzadas por ningún vector de gradiente de la densidad electrónica, lo que equivale a satisfacer la condición:\n\n\\[\n\\nabla \\rho(\\mathbf{r}) \\cdot \\mathbf{n}(\\mathbf{r}) = 0, \\quad \\text{para toda } \\mathbf{r} \\in S(\\Omega)\n\\]\ndonde \\(\\mathbf{r}\\) es el vector de posición y \\(\\mathbf{n}(\\mathbf{r})\\) es el vector unitario normal a la superficie \\(S(\\Omega)\\). Esta condición define claramente los límites de los átomos dentro de una molécula.\nPublicación y Reconocimiento\nEn 1981, Bader publicó su teoría en el libro “Atoms in Molecules: A Quantum Theory” (Bader and Nguyen-Dang 1981). Aunque inicialmente encontró resistencia, su teoría eventualmente ganó aceptación y se convirtió en una herramienta fundamental en la química teórica y computacional.\nAplicaciones de AIM\nOptimización de Geometrías\nLa teoría AIM permite definir átomos y estudiar sus interacciones dentro de una molécula, mejorando así la comprensión de la optimización de geometrías moleculares y la naturaleza de los enlaces químicos.\nAnálisis de Enlaces\nLos puntos críticos de enlace (BCP) son esenciales para caracterizar y entender enlaces covalentes, iónicos y no covalentes. La densidad electrónica en estos puntos y su curvatura proporcionan información crucial sobre la fuerza y naturaleza del enlace. La densidad en un BCP es dada por:\n\\[\n\\rho_{\\text{BCP}} = \\rho(\\mathbf{r}_{\\text{BCP}})\n\\]\nEsta densidad proporciona información sobre la estabilidad y la naturaleza del enlace químico.\nDinámica Molecular y Simulaciones\nAIM se integra en muchos paquetes de software de química computacional, permitiendo realizar análisis topológicos de densidad electrónica en simulaciones de dinámica molecular.\nEjemplo Ilustrativo: El Agua (H₂O)\nCálculo de Densidad Electrónica:\nUtilizamos un método como la DFT para calcular la densidad electrónica de H₂O.\nIdentificación de Puntos Críticos:\nEncontramos puntos críticos en los núcleos de oxígeno e hidrógeno (3,-3) y puntos críticos de enlace (3,-1) entre el oxígeno y cada hidrógeno.\nAnálisis de Enlaces:\nLa densidad en los puntos críticos de enlace nos dice sobre la naturaleza covalente del enlace O-H.\nDefinición de Átomos:\nLas superficies de cero flujo delimitan el oxígeno y los hidrógenos, permitiendo calcular propiedades como la carga atómica integrando sobre estas regiones. La ecuación para la densidad en un punto crítico de enlace es:\n\\[\n\\left. \\frac{\\partial \\rho}{\\partial x_i} \\right|_{\\text{BCP}} = 0 \\quad \\forall i\n\\]\nEsta ecuación indica que el gradiente de densidad electrónica en el punto crítico de enlace (BCP) es cero en todas las direcciones, lo que define claramente la región del enlace y permite analizar sus propiedades.\nImpacto de AIM\nAIM ha tenido un impacto profundo en la química teórica y computacional. Su enfoque riguroso y matemático ha proporcionado una base sólida para estudios de estructura electrónica, reactividad química y diseño de materiales.\n\n\n\nBader, Richard FW, and TT Nguyen-Dang. 1981. Quantum Theory of Atoms in Molecules–Dalton Revisited. Vol. 14. Elsevier.\n\n\nCNCC. 2009. “Photo Credit: Canadian National Committee for Crystallography Newsletter No 1.”\n\n\n\n\n",
    "preview": "posts/AIM/pictures/aim.png",
    "last_modified": "2024-07-07T16:01:22-04:00",
    "input_file": {}
  },
  {
    "path": "posts/us_scripts_files/",
    "title": "Scripts en Bash para realizar cálculos Umbrella Sampling (QM/MM MD)",
    "description": "En este post presento dos scripts que sirven para generar los archivos de entrada para poder correr cálculos de Umbrella Sampling en sistemas proteína-ligando y utilizando la interfaz CHARMM-Gaussian, dado que el nivel de teoría a utilizar será SCC-DFTB/CHARMM.",
    "author": [
      {
        "name": "Camilo Febres-Molina",
        "url": "https://github.com/camilofm"
      }
    ],
    "date": "2022-09-20",
    "categories": [],
    "contents": "\n\n\n\nIndicaciones iniciales\nLos siguientes dos scripts en Bash requieren de otros archivos en los que les proporcionaremos las ventanas de simulación, los frames que corresponden a dichas ventanas de simulación, los archivos ‘input’ plantilla para enviar los cálculos a CHARMM, y finalmente, los archivos ‘input’ que generarán otros archivos necesarios para las dinámicas QM/MM.\nPor lo tanto, los archivos que deben estar en la misma dirección para lograr generar satisfactoriamente las carpetas con los archivos de entrada correspondientes a cada una de las ventanas negativas y positivas son los siguientes:\n01-create_conf-cfm.sh;       <– Los scripts\n02-create_us_eq-cfm.sh;\nnegative_rc.txt;                     <– Y los archivos extras\npositive_rc.txt;\ntraj_frames_neg.txt;\ntraj_frames_pos.txt\nconf_template.inp;\nus_eq_template.inp;\nmakenew_cns.inp;\nmakenew_reg.inp;\nScripts y archivos extra\n01-create_conf-cfm.sh:\n#!/bin/bash\n\n### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n###                                                             ###\n###   This script creates configure files for PMF calculation   ###\n###        Run this script before 02-create_us_eq-cfm.sh        ###\n###       Needs the following things in the same directory:     ###\n###               negative_rc.txt, traj_frames_*.txt,           ###\n###                conf_template.inp, makenew_*inp,             ###\n###                        positive_rc.txt                      ###\n###        (Remember to address the .crd, .psf, .dcd &          ###\n###         parameters files in the conf_template file)         ###\n###   Note: There is a part (mentioned below) that must be      ###\n###         adapted to the number of RC & trajectory frames     ###\n###         of your system.                                     ###\n###   by CFM                                                    ###\n\n### First part: negative RC ###  \n\n#creating negative RC directories & conf_nX.inp files within\ncat negative_rc.txt | while read rc\ndo\n   mkdir n$rc\n   echo \"n$rc directory created ...\"\n   sed -e \"s|RRR|n$rc|g\" conf_template.inp > n$rc/conf_n$rc.inp # changes input & output\n   echo \"n$rc/conf_n$rc.inp file created ...\"\ndone\n\n#generating a temporary file 'rc_tr-neg.txt' to use each number later\ncat negative_rc.txt >> rc_tr-neg.txt\ncat traj_frames_neg.txt >> rc_tr-neg.txt\necho \"rc_tr-neg.txt temporary file created ...\"\n\n#!!! This part must be adapted to the number of RC & trajectory frames of your system !!!#\n#reading RC\nread rc1 < <(sed -n 1p rc_tr-neg.txt)\nread rc2 < <(sed -n 2p rc_tr-neg.txt)\nread rc3 < <(sed -n 3p rc_tr-neg.txt)\nread rc4 < <(sed -n 4p rc_tr-neg.txt)\nread rc5 < <(sed -n 5p rc_tr-neg.txt)\nread rc6 < <(sed -n 6p rc_tr-neg.txt)\nread rc7 < <(sed -n 7p rc_tr-neg.txt)\nread rc8 < <(sed -n 8p rc_tr-neg.txt)\n\n#reading trajectory frames\nread fr1 < <(sed -n 9p rc_tr-neg.txt)\nread fr2 < <(sed -n 10p rc_tr-neg.txt)\nread fr3 < <(sed -n 11p rc_tr-neg.txt)\nread fr4 < <(sed -n 12p rc_tr-neg.txt)\nread fr5 < <(sed -n 13p rc_tr-neg.txt)\nread fr6 < <(sed -n 14p rc_tr-neg.txt)\nread fr7 < <(sed -n 15p rc_tr-neg.txt)\nread fr8 < <(sed -n 16p rc_tr-neg.txt)\n\n#correlating each frame of trajectory with its appropriate RC conf file\nsed -i \"s|TTT|$fr1|g\" n$rc1/conf_n$rc1.inp\necho \"n$rc1/conf_n$rc1.inp file correctly correlated ...\"\nsed -i \"s|TTT|$fr2|g\" n$rc2/conf_n$rc2.inp\necho \"n$rc2/conf_n$rc2.inp file correctly correlated ...\"\nsed -i \"s|TTT|$fr3|g\" n$rc3/conf_n$rc3.inp\necho \"n$rc3/conf_n$rc3.inp file correctly correlated ...\"\nsed -i \"s|TTT|$fr4|g\" n$rc4/conf_n$rc4.inp\necho \"n$rc4/conf_n$rc4.inp file correctly correlated ...\"\nsed -i \"s|TTT|$fr5|g\" n$rc5/conf_n$rc5.inp\necho \"n$rc5/conf_n$rc5.inp file correctly correlated ...\"\nsed -i \"s|TTT|$fr6|g\" n$rc6/conf_n$rc6.inp\necho \"n$rc6/conf_n$rc6.inp file correctly correlated ...\"\nsed -i \"s|TTT|$fr7|g\" n$rc7/conf_n$rc7.inp\necho \"n$rc7/conf_n$rc7.inp file correctly correlated ...\"\nsed -i \"s|TTT|$fr8|g\" n$rc8/conf_n$rc8.inp\necho \"n$rc8/conf_n$rc8.inp file correctly correlated ...\"\n\nrm rc_tr-neg.txt\n#!!! !!! !!! !!! !!! !!! !!! !!! !!! !!!  !!! !!! !!! !!! !!! !!! !!! !!! !!! !!! !!! !!!#\n\n#copying some relevant files down to the nRC directories & executing the conf file\ncat negative_rc.txt | while read rc\ndo\n   cp makenew_*inp n$rc/\n   cp -r toppar* n$rc/ #copying parameters file & directory for the protein\n   cp -r 7kp/ n$rc/ #copying parameters directory for the ligand\n   echo \"Relevant files copied down to n$rc/ directory ...\"\n   echo \"Executing n$rc/conf_n$rc.inp file in charmm...\"\n   cd n$rc\n   /opt/charmm-45b2/exec/gnu_M/charmm < conf_n$rc.inp > conf_n$rc.out\n   cd ..\ndone\n\n###   Second part: positive RC ###\n\n#creating positive RC directories & conf_pX.inp files within\ncat positive_rc.txt | while read rc\ndo\n   mkdir p$rc\n   echo \"p$rc directory created ...\"\n   sed -e \"s|RRR|p$rc|g\" conf_template.inp > p$rc/conf_p$rc.inp # changes input & output\n   echo \"p$rc/conf_p$rc.inp file created ...\"\ndone\n\n#generating a temporary file 'rc_tr-pos.txt' to use each number later\ncat positive_rc.txt >> rc_tr-pos.txt\ncat traj_frames_pos.txt >> rc_tr-pos.txt\necho \"rc_tr-pos.txt temporary file created ...\"\n\n#!!! This part must be adapted to the number of RC & trajectory frames of your system !!!#\n#reading RC\nread rc1 < <(sed -n 1p rc_tr-pos.txt)\nread rc2 < <(sed -n 2p rc_tr-pos.txt)\nread rc3 < <(sed -n 3p rc_tr-pos.txt)\nread rc4 < <(sed -n 4p rc_tr-pos.txt)\nread rc5 < <(sed -n 5p rc_tr-pos.txt)\nread rc6 < <(sed -n 6p rc_tr-pos.txt)\nread rc7 < <(sed -n 7p rc_tr-pos.txt)\nread rc8 < <(sed -n 8p rc_tr-pos.txt)\n\n#reading trajectory frames\nread fr1 < <(sed -n 9p rc_tr-pos.txt)\nread fr2 < <(sed -n 10p rc_tr-pos.txt)\nread fr3 < <(sed -n 11p rc_tr-pos.txt)\nread fr4 < <(sed -n 12p rc_tr-pos.txt)\nread fr5 < <(sed -n 13p rc_tr-pos.txt)\nread fr6 < <(sed -n 14p rc_tr-pos.txt)\nread fr7 < <(sed -n 15p rc_tr-pos.txt)\nread fr8 < <(sed -n 16p rc_tr-pos.txt)\n\n#correlating each frame of trajectory with its appropriate RC conf file\nsed -i \"s|TTT|$fr1|g\" p$rc1/conf_p$rc1.inp\necho \"p$rc1/conf_p$rc1.inp file correctly correlated ...\"\nsed -i \"s|TTT|$fr2|g\" p$rc2/conf_p$rc2.inp\necho \"p$rc2/conf_p$rc2.inp file correctly correlated ...\"\nsed -i \"s|TTT|$fr3|g\" p$rc3/conf_p$rc3.inp\necho \"p$rc3/conf_p$rc3.inp file correctly correlated ...\"\nsed -i \"s|TTT|$fr4|g\" p$rc4/conf_p$rc4.inp\necho \"p$rc4/conf_p$rc4.inp file correctly correlated ...\"\nsed -i \"s|TTT|$fr5|g\" p$rc5/conf_p$rc5.inp\necho \"p$rc5/conf_p$rc5.inp file correctly correlated ...\"\nsed -i \"s|TTT|$fr6|g\" p$rc6/conf_p$rc6.inp\necho \"p$rc6/conf_p$rc6.inp file correctly correlated ...\"\nsed -i \"s|TTT|$fr7|g\" p$rc7/conf_p$rc7.inp\necho \"p$rc7/conf_p$rc7.inp file correctly correlated ...\"\nsed -i \"s|TTT|$fr8|g\" p$rc8/conf_p$rc8.inp\necho \"p$rc8/conf_p$rc8.inp file correctly correlated ...\"\n\nrm rc_tr-pos.txt\n#!!! !!! !!! !!! !!! !!! !!! !!! !!! !!!  !!! !!! !!! !!! !!! !!! !!! !!! !!! !!! !!! !!!#\n\n#copying some relevant files down to the pRC directories & executing the conf file\ncat positive_rc.txt | while read rc\ndo\n   cp makenew_*inp p$rc/\n   cp -r toppar* p$rc/ #copying parameters file & directory for the protein\n   cp -r 7kp/ p$rc/ #copying parameters directory for the ligand\n   echo \"Relevant files copied down to p$rc/ directory ...\"\n   echo \"Executing p$rc/conf_p$rc.inp file in charmm...\"\n   cd p$rc\n   /opt/charmm-45b2/exec/gnu_M/charmm < conf_p$rc.inp > conf_p$rc.out\n   cd ..\ndone\n\necho \"Done.\"\n\n###                                                             ###\n###                       End of this script                    ###\n###                                                             ###\n### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n02-create_us_eq-cfm.sh:\n#!/bin/bash\n\n### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n###                                                             ###\n###  This script creates equilibration files for US - QM/MM MD  ###\n###             Run this after 01-create_conf-cfm.sh            ###\n###            Additionally needs the following files           ###\n###                      in the same directory:                 ###\n###                 us_eq_template.inp, sccdftb.dat             ###\n###          (Remember to define your qm zone, charge &         ###\n###         other parameters in the us_eq_template file)        ###\n###   by CFM                                                    ###\n\n### First part: negative RC ###  \n\n#creating the eq_nX.inp file & copying sccdftb.dat file\ncat negative_rc.txt | while read rc\ndo\n   d1=`echo $rc | cut -b 1`\n   d2=`echo $rc | cut -b 2`\n   sed -e \"s|TTT|-$d1.$d2|g\" us_eq_template.inp > n$rc/eq_n$rc.inp   #putting the RC\n   sed -i \"s|RRR|n$rc|g\" n$rc/eq_n$rc.inp   #changing the input & output\n   echo \"n$rc/eq_n$rc.inp file created ...\"\n   cp sccdftb.dat n$rc\ndone\n\n### Second part: positive RC ###\n\n#creating the eq_pX.inp file & copying sccdftb.dat file\ncat positive_rc.txt | while read rc\ndo\n   d1=`echo $rc | cut -b 1`\n   d2=`echo $rc | cut -b 2`\n   sed -e \"s|TTT|$d1.$d2|g\" us_eq_template.inp > p$rc/eq_p$rc.inp   #putting the RC\n   sed -i \"s|RRR|p$rc|g\" p$rc/eq_p$rc.inp   #changing the input & output\n   echo \"p$rc/eq_p$rc.inp file created ...\"\n   cp sccdftb.dat p$rc\ndone\n\necho \"Done.\"\n\n###                                                             ###\n###                       End of this script                    ###\n###                                                             ###\n### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\nA continuación se muestran ejemplos arbitrarios de los archivos extra arriba mencionados:\nnegative_rc.txt:\ntraj_frames_neg.txt:\nconf_template.inp:\n!Configuracion para crear esfera con zonas definidas, para hacer umbrella sampling - example\n\nbomlev -1\nset d .\nset stream ~/utils/stream\nset input RRR\nset output RRR\n\nstream toppar_wo.str\n\nopen read form unit 1 name ~/umbrella/gtfwt_cryst.psf\nREAD psf card unit 1\nclose unit 1\n\nopen read form unit 1 name ~/umbrella/prod.crd\nREAD coord card unit 1\nclose unit 1\n\n! .1define the substrate stereocenter as the origin of coordinates\ndefine cntr1 sele segid HETA .and. type C1 end\n\n! .2moving\ncoor stat sele cntr1 end\ncoor translate xdir -?xave ydir -?yave zdir -?zave sele all end\n\n! .3checking center\ncoor stat sele cntr1 end\n\nopen read unit 3 file name ~/umbrella/path.dcd\nread coord file unit 3 ifile TTT\nclose unit 3\n\ndele atom sele .byres. ( .not. ( point 0.0 0.0 0.0 cut 30.0)) end\n\n!-----------regions\nset xcen     0.0\nset ycen     0.0\nset zcen     0.0\nset rsphere 25.0         ! radius of the spherical region of interest\nset rexcl    2.0         ! water exclusion radius\nset rgeo     4.0         ! to setup the MMFP potential\ncalc rwater  = @rsphere - @rexcl\ncalc rdroff  = @rsphere - @rgeo\nset temp   310.0 !for lang region\n\nstream @stream/writeall.inp\nstream @stream/input.inp\nstream makenew_reg.inp\nstream makenew_cns.inp  \n\nend\nus_eq_template.inp:\n! Equilibrium MD for umbrella sampling - example\n\nbomlev -2\n!----files\nset input RRR\nset output RRR\nset loadcrd  0 !load @restart.crd before any min or md\nset loadres  0 !load @restart.res before any min or md\nset loadpdb  0 !load @restart.res before any min or md\n!set mijinp   1v54.fsph30.mij.25.mij\n!set phiinp   1v54.fsph30.phi\n!----directories\nset d .\nset stream ~/utils/stream\n\n!-----keywords\nset kumb 100.0\nset del0 TTT\n!-----------elec options\nset nbond ext\n!set nbond atcut\n!set polgsbp 25\n!-----------min op\nset minon  0\nset minrun abnr\nset minstep 50\nset minprint 1\nset mintolg 0.01\n!-----------md op\nset mdon  1\nset mdrun  start\n!set mdseed 314159\nset mdtype lang\nset timest 0.001\nset mdstep 10000\nset mdfirst 100\nset mdtemp 310\nset ieqfrq 500.0 !higher than 0.0 for equilibration\n!\n!-----------regions (consistens with regions/constants file)\nset xcen     0.0\nset ycen     0.0\nset zcen     0.0\nset rsphere 25.0         ! radius of the spherical region of interest\nset rexcl    2.0         ! water exclusion radius \nset rgeo     4.0         ! to setup the MMFP potential + Langevin(buffer) zone\ncalc rwater  = @rsphere - @rexcl\ncalc rdroff  = @rsphere - @rgeo\n\nstream toppar_wo.str\n\nstream @stream/input.inp\n\nstream @stream/nbond_atcut.inp\n!set langevin environment\nstream @stream/sbc.inp\n!what is fixed and what moves (consistent with sbc)\n! apply regdef and mmfp altogether\nstream @stream/regdef.inp !fix(3-bonds rule) and scale 0.0 charges\n!cons fix sele resname CU2 end ! CUa is very close to the edge we dont have parameter\nstream @stream/mmfp_sph.inp\n\ndefine asp sele segid PROA .and. resid 477 .and.( .not. (type CA .or. type HA -\n .or. type N .or. type HN .or. type C .or. type O )) end\n\ndefine glup sele segid PROA .and. resid 515 .and.( .not. (type CA .or. type HA - \n .or. type N .or. type HN .or. type C .or. type O )) end\n\ndefine asp2 sele segid PROA .and. resid 588 .and.( .not. (type CA .or. type HA -\n .or. type N .or. type HN .or. type C .or. type O )) end\n\ndefine wo67 sele segid HETB .and. resid 1167 end\n\ndefine wo96 sele segid HETB .and. resid 1196 end\n\ndefine qm sele asp .or. glup .or. segid HETA .or. asp2 .or. wo67 .or. wo96 end\n\nscalar WMAIN set 1.0 sele (qm) .and. type O*  SHOW end\nscalar WMAIN set 2.0 sele (qm) .and. type N*  SHOW end\nscalar WMAIN set 3.0 sele (qm) .and. type C*  SHOW end\nscalar WMAIN set 4.0 sele (qm) .and. type H*  SHOW end\nscalar WMAIN set 4.0 sele (qm) .and. type QQ*  SHOW end\n\nSCCDFTB remove CHRG -2 SELE QM END TEMP 0.00 SCFT 0.00000001  D3RD HBOND\n\n!------Load current geom--\nif loadcrd lt 1 goto noloadcrd\nopen read unit 3 card name @d/@restart.crd\nread coor card unit 3\nclose unit 3\n\nlabel noloadcrd\n!------Load current geom--\nif loadres lt 1 goto noloadres\nopen read unit 3 card name @d/@restart.res\nread coor dynr curr unit 3\nclose unit 3\n\nlabel noloadres\n!------Load current geom--\nif loadpdb lt 1 goto noloadpdb\nopen read unit 3 card name @d/@restart.pdb\nread coor pdb unit 3\nclose unit 3\n\nlabel noloadpdb\n\nopen write unit 3 card name @output.qm.pdb\nwrite coor pdb sele qm end unit 3\nclose unit 3\n\nrxncor: define o1   point sele atom HETA 1 O1 end\nrxncor: define c1   point sele atom HETA 1 C1 end\nrxncor: define oasp point sele atom PROA 477 OD1 end\nrxncor: define a3   dist o1 c1\nrxncor: define a4   dist c1 oasp\n\nrxncor: define RC combin a3 1.0 a4 -1.0\nrxncor: set nrxn 1 RC\n\nopen unit 29 form write name  @d/@output.rc\n\nrxncor: trace RC unit 29\n\nrxncor: umbrella name RC kumb @kumb del0 @del0 form 1 \nrxncor: statistics name RC lowdelta -1.7 hidelta 1.5 deldel 0.1 start 1000\n!energy\n!-------MIN -------------\nif minon lt 1 goto nomin\n!open write unit 11 uform name @output.min.dcd\n!mini @minrun nstep @minstep nprint @minprint tolg @mintolg iuncrd 11 nsavc 3\nmini @minrun nstep @minstep nprint @minprint tolg @mintolg\n\nlabel nomin\n\nif mdon lt 1 goto nomd\n!shake bonh tolerance 1.0e-06 MXIT 1500\n\nopen unit 24 form read  name @d/@restart.res\nopen unit 25 form write name @d/@output.res\nopen unit 26 file write name @d/@output.dcd\nopen unit 21 form write name @d/@output.static \n\ndynamics @mdtype @mdrun timestep @timest nstep @mdstep nprint 10 iprfrq 500 -\n    firstt @mdfirst finalt @mdtemp tstruc @mdtemp TEMINC 5.0 twindl -10.0 twindh 10.0 -\n    IHTFRQ 0 IEQFRQ @ieqfrq NTRFRQ 0 ISVFRQ 100 -\n    IASORS 0 IASVEL 1 ISCVEL 0 ICHECW 0 ISEED iseed -\n    iunrea 24 iunwri 25 iuncrd 26 iunvel -1 kunit 20 nsavc 100 nsavv 0 -\n    inbfrq -1 imgfrq 0 ilbfrq -1 ihbfrq 0 tbath @mdtemp rbuffer @rdroff\n\nrxncor: write unit 21\nclose unit 21\nclose unit 25\nclose unit 26\n\nlabel nomd\n\nopen write unit 3 card name qm.@output.pdb\nwrite coor pdb sele qm end unit 3\nclose unit 3\n\nstream @stream/write.inp\n\nstop\nmakenew_cns.inp\n* constraints\n*\nOPEN UNIT 3 NAME @d/@input.reg READ FORM\nREAD  COOR COMP CARD UNIT 3\nCLOSE UNIT 3\n\n\n! atoms beyond 18A will be held fixed, so only need to add constraints to\n! buffer region atoms within that cutoff\n!set 1 20.0    ! radius for fully mobile region\n!set 2 24.0    ! radius of inner region\n!set 3 22.0    ! radius of buffer region where Langevin dynamics will be used\n\n! Setting various boundary flags\nscalar xcomp store 1    ! initial md region\nscalar ycomp store 2    ! initial buffer region\nscalar zcomp store 3    ! initial Langevin atoms-proteins only\nscalar wcomp store 4    ! reservoir region atoms\n\n! Convert crystallographic thermal factors in wmain to constraint forces\nscalar wmain reci sele recall 3 end               ! get 1/B\nscalar wmain mult 0.001987191 sele recall 3 end   ! k(boltz)/B\nscalar wmain mult @temp sele recall 3 end         ! kT/B\nscalar wmain mult 4.0 sele recall 3 end           ! 4kT/B\nscalar wmain mult 9.87 sele recall 3 end          ! 4(pi**2)kT/B\nscalar wmain set 0.0 sele .not. recall 3 end      ! zero out the rest\nscalar wmain store 5\n\nscalar xcomp set 0.0 sele all end\nscalar ycomp set 0.0 sele all end\nscalar zcomp set 0.0 sele all end\nscalar wcomp set 0.0 sele all end\n\nscalar xcomp recall 3                    ! langevin region constraint flags\nscalar zcomp set 1.0 sele recall 3 .or. (resn TIP3 .and. type OH2) end\nscalar zcomp mult 80.0 sele recall 3 end                     ! protein friction\nscalar zcomp mult 80.0 sele (resn TIP3 .and. type OH2) end   ! TIP3 friction\nscalar ycomp recall 5                    ! unscaled constraint force constants\nscalar wcomp recall 1\n\nopen unit 15 write form name  @d/@output.cnu\nwrite coor comp card unit 15\n* col. 1: langevin region constraint flags\n* col. 2: UNSCALED langevin region harmonic constraint forces\n* col. 3: langevin friction coefficients.\n* col. 4: MD region flags.\n*\n! ****** Scale the constraints based on where the atoms are ******\n! Values of S(r) for scaling the constraint forces\n\nset 4 0.00 !inner langevin region\nset 5 0.08 !next\nset 6 0.20 !next\nset 7 0.32 !next\nset 8 0.44 !next\nset 9 0.50 !next\n\n!calc zones for scaling\ncalc lang = @rsphere - @rdroff\ncalc lang4 = @rdroff \ncalc lang5 = @rdroff + 0.5\ncalc lang6 = @rdroff + 1.0\ncalc lang7 = @rdroff + 1.5\ncalc lang8 = @rdroff + 2.0\n\n!force constant scaling\nscalar xcomp store 1\nscalar ycomp mult @4 sele ( recall 1 .and. point @xcen @ycen @zcen cut @lang4 ) end\nscalar ycomp mult @5 sele ( recall 1 .and. point @xcen @ycen @zcen cut @lang5 -\n                            .and. .not. point @xcen @ycen @zcen cut @lang4 ) end\nscalar ycomp mult @6 sele ( recall 1 .and. point @xcen @ycen @zcen cut @lang6 -\n                            .and. .not. point @xcen @ycen @zcen cut @lang5 ) end\nscalar ycomp mult @7 sele ( recall 1 .and. point @xcen @ycen @zcen cut @lang7 -\n                            .and. .not. point @xcen @ycen @zcen cut @lang6 ) end\nscalar ycomp mult @8 sele ( recall 1 .and. point @xcen @ycen @zcen cut @lang8 -\n                            .and. .not. point @xcen @ycen @zcen cut @lang7 ) end\nscalar ycomp mult @9 sele ( recall 1 .and. .not. point @xcen @ycen @zcen cut @lang8 ) end\n\n!friction scaling\nscalar zcomp mult @4 sele (recall 1 .and. point @xcen @ycen @zcen cut @lang4 -\n       .and. .not. resn TIP3) end\nscalar zcomp mult @5 sele (recall 1 .and. point @xcen @ycen @zcen cut @lang5 -\n       .and. .not. (point @xcen @ycen @zcen cut @lang4 .or. resn TIP3)) end\nscalar zcomp mult @6 sele (recall 1 .and. point @xcen @ycen @zcen cut @lang6 -\n       .and. .not. (point @xcen @ycen @zcen cut @lang5 .or. resn TIP3)) end\nscalar zcomp mult @7 sele (recall 1 .and. point @xcen @ycen @zcen cut @lang7 -\n       .and. .not. (point @xcen @ycen @zcen cut @lang6 .or. resn TIP3)) end\nscalar zcomp mult @8 sele (recall 1 .and. point @xcen @ycen @zcen cut @lang8 -\n       .and. .not. (point @xcen @ycen @zcen cut @lang7 .or. resn TIP3)) end\nscalar zcomp mult @9 sele (recall 1 .and. .not. -\n       (point @xcen @ycen @zcen cut @lang8 .or. resn TIP3)) end\n\nopen unit 14 write form name @d/@output.cns\nwrite coor comp card unit 14\n* col. 1: langevin region constraint flags\n* col. 2: SCALED langevin region harmonic constraint forces\n* col. 3: SCALED langevin friction coefficients.\n* col. 4: MD region flags.\n\nstop\nmakenew_reg.inp\n* center at Cu\n*\n! atoms beyond ? will be held fixed, so only need to add constraints to\n! buffer region atoms within that cutoff\n!set 1 20.0    ! radius for fully mobile region\n!set 2 24.0    ! radius of inner region\n!set 3 22.0    ! radius of buffer region where Langevin dynamics will be used\n!set 1 @rdroff    ! radius for fully mobile region\n!set 2 @rsphere   ! radius of inner region\n!set 3 @rwater    ! radius of buffer region where Langevin dynamics will be used\n\n!all comments were written in a 24/22/20 partition. but the input is general\n\nscalar xcomp set 0.0\nscalar ycomp set 0.0\nscalar zcomp set 0.0\nscalar wcomp set 0.0\n\n! INNER, MOBILE REGION\n! residues with at least one atom within 20-A and\n!   with no main chain atoms outside of 22-A\nscalar xcomp set 1.0 -\n         sele  ( .byres. ( point @xcen @ycen @zcen cut @rdroff ) ) -\n        .and. .not. (( type C  .or. type O  .or. type N .or. -\n                      type CA .or. type HA .or. type HN) -\n        .and. .not. ( point @xcen @ycen @zcen cut @rwater )) end\nscalar xcomp store 1\n\n! INITIAL BUFFER REGION\n! residues with at least one atom within 24-A,  but not already\n!  included in the inner, mobile region\nscalar ycomp set 1.0 sele ( .byres. ( point @xcen @ycen @zcen cut @rsphere ) ) -\n        .and. .not. recall 1 end\nscalar ycomp store 2\n\n! PROTEIN LANGEVIN ATOMS\n! all atoms, except hydrogens and waters in the buffer region\nscalar zcomp set 1.0 sele recall 2 .and. .not. -\n        ( hydrogen .or. lone .or. resname tip3 ) end\nscalar zcomp store 3\n\n! OUTER REGION ATOMS\n! any atom not in the inner or buffer regions\nscalar wcomp set 1.0 sele .not. (recall 1 .or. recall 2 ) end\nscalar wcomp store 4\n!write out the new psf and crd, as well as partition.\n\nopen unit 13 write form name @d/@output.reg\nwrite coor card comp unit 13\n* column 1: reaction region 16 A by residue partioning\n* column 2: Buffer region atoms, any atoms (byres) within @rsphere A but\n*           not in @rdroff A plus all main chain atoms outside @rwater A\n* column 3: Protein Langevin atoms (same as col. 2 but no H or tip3).\n* column 4: Outer region atoms\n*\n\nreturn\nFinalmente, cabe destacar dos cosas:\nSe debe recordar direccionar correctamente los archivos de coordenadas (.crd), de topología (.psf), trayectoria (.dcd) y los parámetros en el archivo conf_template.inp\nPara ejecutar los scripts en bash, primero se les debe dar permiso de ejecución, por ejemplo, así: chmod +x 01-create_conf-cfm.sh y luego correrlos de la siguiente manera: ./01-create_conf-cfm.sh\nTodo lo anterior generará las carpetas y los archivos necesarios para poder realizar Umbrella Sampling (QM/MM MD) utilizando la interfaz CHARMM-Gaussian.\n\n\n\n",
    "preview": "posts/us_scripts_files/pictures/code.png",
    "last_modified": "2024-11-24T01:33:02-03:00",
    "input_file": {}
  },
  {
    "path": "posts/tutorial_bfee/",
    "title": "Estimador de Energía Libre de Unión para sistemas proteína-ligando (BFEE - Plugin de VMD): Tutorial de uso",
    "description": "Aquí veremos cómo utilizar el Plugin BFEE de VMD de manera sencilla para generar archivos de entrada y así poder correr los cálculos MD del sistema en estudio y así obtener el &Delta;Gº de unión por medio del Potencial de Fuerza Medio (PMF).",
    "author": [
      {
        "name": "Camilo Febres-Molina",
        "url": "https://github.com/camilofm"
      }
    ],
    "date": "2022-09-01",
    "categories": [],
    "contents": "\nEste tutorial fue realizado en colaboración con Leslie Sanchez.\n\n\n\n\nEl plugin BFEE permite la generación de archivos de entrada para realizar el cálculo de ΔG absoluto de unión en NAMD usando variables colectivas (Fu et al. 2018). Los archivos de entrada se generan en el software VMD, con lo cual se generarán los archivos necesarios para realizar los cálculos de 8 carpetas. Posteriormente, el plugin permite el procesamiento de los datos.\nEl plugin se debe descargar desde la SI del artículo colocado en la sección final de Referencias, y que titula: “BFEE: A User-Friendly Graphical Interface Facilitating Absolute Binding Free-Energy Calculations”.\nEn la SI también se encuentran las instrucciones de instalación tanto para Windows como para Linux y OSX. (En nuestra experiencia este Plugin responde mejor en Ubuntu que en Windows.)\nGeneración de inputs:\nUna vez instalado el plugin en VMD aparecerá en “extensions → my plugins → BFEE”. Para su uso es necesario tener archivos del sistema a trabajar equilibrado, ya que para generar los inputs se requieren los siguientes archivos del sistema → *.psf, *.coor, *.vel, *.xsc y los archivos de parámetros necesarios para el sistema en cuestión.\nEl plugin es bastante user-friendly, por lo que, al abrirlo se entiende dónde hay que poner los archivos requeridos, luego hay que pinchar la opción “generar inputs”, a partir de lo cual se generarán 8 carpetas, las cuales se deben transferir al cluster donde esté instalado NAMD.\nCorrer los archivos en NAMD:\nEn cada carpeta habrá un archivo de configuración “abf.conf” que es el que contiene la información para correr el cálculo, del cual no es necesario modificar nada.\nAdemás, en cada carpeta existe el archivo colvar.in, que tiene la información de las variables colectivas. Luego de algunos ensayos se observó que es necesario agregar los keywords “lowerWall” y “upperWall” luego de la información de lower y upperboundary, (los valores de los keywords mencionados deben ser iguales, como se muestra a continuación en un ejemplo:\n\n\n\nCon esto listo se deben correr las carpetas desde la 001 a la 008 de forma sucesiva.\nNota: Considerar lo siguiente, la carpeta 007 consiste de una solvatación extra del sistema, por lo cual el plugin construye un nuevo psf y pdb donde la caja de agua es más extensa en tamaño, con lo cual crece el número de átomos (en algunos casos al triple). De esto se ha observado que en proteínas donde el número de átomos supere los ~150 - 200 mil átomos, el cálculo no se llevará a cabo, dado que se generan errores (al menos en la versión de NAMD que se tiene actualmente instalada en el cluster UDEC) por lo cual será necesario hacer modificaciones en el archivo de la carpeta 007 en caso de que se genere una proteína con un número de átomos muy grande.\nSe ha seguido la siguiente metodología en carpeta 007 para llevar a cabo el cálculo:\nTomando como base el archivo bound.psf, bound.coor.pdb (carpeta 007_r), los archivos solvated.psf y solvated.pdb, ligand.pdb y protein.pdb fueron editados para reducir la cantidad de átomos (remover las moléculas de agua adicionales). Por lo que se realizó lo siguiente:\nLos archivos bound.psf, bound.coor.pdb, se copiaron a solvated.psf y solvated.pdb. En el archivo solvated.pdb se agregó 1.00 en la columna A.\nSe tomó ligand.pdb de la carpeta 006 y se copió por ligand.pdb en la carpeta 007_r. Se agregó 1.00 en la columna A.\nSe tomó protein.pdb de la carpeta 006 y se copió por protein.pdb en carpeta 007_r. Se agregó 1.00 en la columna A.\nDebido a que el archivo solvated.pdb ahora es un sistema más pequeño se deben cambiar los valores de tamaño de celda en el archivo abf.conf, para lo cual se utiliza VMD para calcular los valores de celda y centro del sistema (tkconsole, comandos measure minmax y measure center).\nProcesamiento de datos:\nUna vez finalizado el cálculo en las 8 carpetas se observará que cada carpeta contiene una carpeta “output” donde se fueron escribiendo diferentes archivos de salida, entre ellos una trayectoria *.dcd y el archivo que permitirá obtener el valor de energía libre, *.czar.pmf, los cuales se deben cargar en la ventana del plugin “analyze” y luego pinchar “compute binding free energy” con lo cual se obtendrá el valor final de energía libre absoluta (a continuación se incluye una imagen de la ventana del plugin donde se deben cargar los respectivos outputs).\n\n\n\n\n\n\nFu, Haohao, James C Gumbart, Haochuan Chen, Xueguang Shao, Wensheng Cai, and Christophe Chipot. 2018. “BFEE: A User-Friendly Graphical Interface Facilitating Absolute Binding Free-Energy Calculations.” Journal of Chemical Information and Modeling 58 (3): 556–60.\n\n\n\n\n",
    "preview": "posts/tutorial_bfee/pictures/bfee.png",
    "last_modified": "2024-11-23T23:30:16-03:00",
    "input_file": {}
  },
  {
    "path": "posts/tutorial_gromacs/",
    "title": "Análisis post producción de la dinámica molecular con Gromacs - Tutorial",
    "description": "Aquí veremos paso a paso cómo es que podemos utilizar la suite Gromacs para el análisis post producción de una dinámica molecular realizada con los programas Gromacs, CHARMM o NAMD.",
    "author": [
      {
        "name": "Dr. Camilo Febres-Molina",
        "url": "https://github.com/camilofm"
      }
    ],
    "date": "2022-08-25",
    "categories": [],
    "contents": "\n\n\n\nExisten muchas metodologías, softwares y servidores en línea diseñados para analizar la trayectoria obtenida luego de la producción de una dinámica molecular (MD) para, así, obtener información que dé cuenta de la estabilidad de dicha corrida en un período específico, las fluctuaciones de ciertos residuos, entre otros.\nSin embargo, el paquete de software Gromacs nos permite, en un solo lugar, realizar todos estos análisis y muchos otros de forma relativamente simple y utilizando la línea de comandos (Abraham et al. 2015; Páll et al. 2020).\nEl presente tutorial abarcará los siguientes análisis post producción de la MD:\nRMSD\nRMSF, factor-B y estructura promedio\nRadio de giro\nSASA y energía libre de solvatación estimada\nMediciones: distancias, ángulos y diedros\nEstructura secundaria\nDensidad\nEnlaces de hidrógeno\n\nIndicaciones y recomendaciones iniciales\n\nAntes de iniciar con los diferentes análisis se debe tener en cuenta que la trayectoria a utilizar sea la óptima, por ejemplo, que no contenga “saltos” o algunas moléculas que parecieran estar “rotas” debido a la periodicidad de contorno (PBC) durante la MD.\nPor lo que es una buena práctica realizar la revisión de dicha trayectoria (en algún visualizador, como VMD) o, en su defecto, utilizar el programa trjconv para restaurar dichos “saltos” o “rupturas” como veremos en el punto 2.\nA lo largo de este tutorial, y a modo de ejemplo, se utilizarán los siguientes archivos de entrada iniciales: coor.pdb, traj.dcd y topol.psf (suponiendo que son estos archivos con sus extensiones los que se obtuvieron al realizar la MD luego de correrlos en NAMD o AMBER, por ejemplo).\nLo primero que se debe hacer es convertir la trayectoria traj.dcd a un formato que gromacs utilice y pueda manejar, como traj.trr o traj.xtc, por lo que a través del programa VMD, y luego de cargar toda la trayectoria (topol.psf + traj.dcd), se guardará dicha trayectoria (en “File” -> “Save coordinates” -> “File type”) con la extensión “trr”.\nEl único inconveniente al convertir la trayectoria a este formato, y no obtenerlo de forma nativa (habiendo corrido la MD con Gromacs), es que las etiquetas de tiempo deberán corregirse luego con el graficador que utilicemos (por ejemplo, con Grace).\nTratamiento adecuado de la trayectoria\nEl programa trjconv se utiliza básicamente para convertir la trayectoria trr (generalmente pesada) en otra comprimida y más manejable xtc. Además también se utilizará a continuación para reparar algún problema de PBC en la trayectoria inicial.\nEn la misma carpeta en la que estén los archivos de entrada que se tienen hasta ahora (y donde debe estar también traj.trr) se generará un archivo pdb con las coordinadas del frame inicial de la trayectoria (también se puede utilizar VMD para esto) y se llamará coor-tpr.pdb, esto con la intención de utilizarlo en vez del archivo tpr que requieren todos los programas de Gromacs y que sirve de coordenadas de referencia.\nUna vez hecho esto, y en la mencionada carpeta, se correrá la siguiente línea de comando en la terminal:\ngmx trjconv -f traj.trr -s coor-tpr.pdb -o traj.xtc -pbc mol -ur compact -center\n-> Para centrar, escoger la opción “proteína” y como salida la opción “sistema”.\nCon lo que el archivo de salida aquí será traj.xtc y es el que se utilizará de ahora en adelante para los siguientes análisis.\nCabe mencionar aquí que así no existan problemas de “saltos” o “rupturas” en nuestra trayectoria original (traj.dcd) es una buena práctica utilizar las opciones -pbc mol, -ur compact y -center, ya que no afectarán en nada en el caso de que no se necesiten.\nRMSD\nSe correrá la siguiente línea de comando para generar un archivo para ser posteriormente graficado:\ngmx rms -f traj.xtc -s coor-tpr.pdb -o rmsd.xvg\n-> Aquí se escogerá a la “proteína” en ambas opciones para que el cálculo de la desviación media cuadrática sea para esa estructura únicamente y no para todo el sistema.\nUna vez generado el archivo de salida rmsd.xvg se podrá utilizar un programa (por defecto el formato de dicho archivo es para el programa Grace) para obtener la gráfica RMSD de la proteína a lo largo de la MD. Como se mencionó en el punto 1, se debe corregir la etiqueta del tiempo en dicho graficador (que por defecto está en ps).\nNota: En el caso de que, aún habiendo realizado el comando del punto 2, se visualice un salto abrupto (anormal) en la gráfica del RMSD, se puede correr las siguientes líneas de comando para intentar arreglar el problema:\ngmx trjconv -f traj.xtc -s coor-tpr.pdb -o traj_no-jump.xtc -pbc nojump\ngmx trjconv -f traj_no-jump.xtc -s coor-tpr.pdb -o traj_fit.xtc -fit rot+trans\nHaciendo esto y luego recalculando el RMSD con:\ngmx rms -f traj_fit.xtc -s coor-tpr.pdb -o rmsd_fit.xvg\nSe obtendrá el nuevo archivo de salida rmsd_fit.xvg con el cual muy probablemente ya se pueda generar una gráfica RMSD corregida y sin saltos anormales. Sólo si éste es el caso, entonces para lo que resta del tutorial se deberá utilizar el archivo traj_fit.xtc cada que se vea traj.xtc ya que es el corregido.\nEn el caso de que la primera gráfica (aquella generada con rmsd.xvg) esté sin anormalidades se utilizará el archivo traj.xtc para lo que resta de los análisis.\nRMSF, factor-B y estructura promedio\nA continuación se generarán archivos para poder graficar las fluctuaciones por residuo, un pdb que contiene en la columna beta la información sobre dichas fluctuaciones para luego poder representarlo en colores (en VMD, por ejemplo) y otro pdb que contendrá las coordenadas de la estructura promedio de la trayectoria (o segmento que se escoja de ella).\nPrimero, a través de la gráfica del RMSD anterior, se seleccionará la parte de la trayectoria que sea estable para utilizarla. Recordar que por defecto Gromacs utiliza los ps como unidad de tiempo, por lo que se debe conocer el intervalo estable de la mencionada trayectoria en ps (se puede lograr esto viendo el eje x en el gráfico RMSD antes de haber corregido los tiempos a ns, como se mencionó en los puntos 1 y 3).\nPara esto, se correrá la siguiente línea de comando:\ngmx rmsf -f traj.xtc -s coor-tpr.pdb -oq coor_bfac.pdb -ox coor_avrg.pdb -o rmsf.xvg -res -b A -e B\n-> Se deberá escoger sólo la proteína para realizar el cálculo.\n-> A y B son los tiempos (en ps) del primer y último frame, respectivamente, para ser leídos de la trayectoria completa. Por ejemplo, en el caso que se tenga una trayectoria total de 10 ps (probablemente de 100 ns - recordar que así lee Gromacs las trayectorias que originalmente son dcd y se convirtieron a trr en VMD) y se sepa que la parte estable es a partir del ps 4.5 (ns 45) hasta el final, entonces, los valores de A y B para la anterior línea de comando serían 4.5 y 10, respectivamente.\nDe esta manera se podrá graficar el archivo de salida rmsf.xvg para obtener el RMSF (por residuo). Así como también se habrán generado los archivos coor_bfac.pdb y coor_avrg.pdb los que dan cuenta de las coordenadas de la proteína (de referencia - frame inicial) con el factor-B y coordenadas de la estructura promedio, respectivamente, únicamente del intervalo de la trayectoria antes escogido.\nRadio de giro\nCalcular el radio de giro de una proteína sobre los ejes x, y, z como función del tiempo es útil para conocer el grado de compactación que pudo haber sufrido esta estructura a lo largo de la trayectoria.\nSe correrá la siguiente línea de comando:\ngmx gyrate -f traj.xtc -s coor-tpr.pdb -o rg.xvg -b A -e B\n-> Se deberá escoger sólo la proteína.\n-> Siendo A y B los mismos tiempos (en ps) utilizados en el punto 4.\nAsí, esto nos arrojará un archivo de salida rg.xvg el que se podrá graficar.\nCabe mencionar que se le llama “radio de giro” pues luego de calcular la ponderación por masa de cada átomo en el espacio, dichos puntos se comparan frame a frame con el centro de masa de toda la proteína (a modo de colocar esta proteína dentro de una esfera) y el “radio” resultante más alejado del centro es aquel que se asigna en cada frame; finalmente, y a groso modo, se obtienen así las dos columnas del archivo rg.xvg.\nSASA y energía libre de solvatación estimada\nCon la siguiente línea de comando se calculará tanto el área superficial accesible al solvente (también conocida como superficie molecular de Lee-Richards) de toda la proteína, como también la energía libre de solvatación estimada como función del tiempo:\ngmx sasa -f traj.xtc -s coor-tpr.pdb -o sasa.xvg -odg delta-g_solv.xvg -b A -e B\n-> Se deberá escoger sólo la proteína.\n-> Siendo A y B los mismos tiempos (en ps) utilizados en el punto 4.\nCon los archivos de salida generados, sasa.xvg y delta-g_solv.xvg, se podrá graficar la superficie de Lee-Richards y la energía libre de solvatación estimada (con unidades de kJ·mol-1·nm-2), respectivamente, dentro del intervalo de la trayectoria escogido.\nMediciones a lo largo de la trayectoria\nExisten diversas formas de realizar mediciones entre átomos, ya sean distancias lineales entre ellos, ángulos o diedros.\nPara realizar estas mediciones es necesario generar un archivo index.ndx con el programa make_ndx, así:\ngmx make_ndx -f coor-tpr.pdb -o index.ndx\n-> En el que se escogerán átomos o residuos que se desee medir creando así un “grupo nuevo” con la selección de dicho elemento. Cabe recordar que serán dos grupos para la medición de distancias, tres grupos para medir ángulos y cuatro grupos para la medición de ángulos diedros.\nDistancias\nSi se desea medir la distancia entre dos átomos o dos residuos, estos últimos por medio de su centro de masa (com), la línea de comando deberá ser algo así:\ngmx distance -f traj.xtc -s coor-tpr.pdb -n index.ndx -oav distance.xvg -select “com of group X plus com of group Y” -b A -e B\n-> Donde X y Y son los grupos (que poseen un elemento cada uno) que se desea medir, sean éstos un par de átomos (no habrá problema con que se calcule el centro de masa de un átomo, pues serán las mismas coordenadas) o un par de residuos.\n-> Siendo A y B los mismos tiempos (en ps) utilizados en el punto 4.\nDe esta manera se podrá graficar el archivo de salida distance.xvg y así conocer la distancia entre éstos elementos a lo largo de la trayectoria escogida.\nÁngulos\nPara este caso, la línea de comando sería así:\ngmx gangle -f traj.xtc -n index -g1 angle -oav angles.xvg -group1 “com of group X plus com of group Y plus com of group Z” -b A -e B\n-> Donde X, Y y Z son los grupos con los elementos que se desee medir.\n-> Siendo A y B los mismos tiempos (en ps) utilizados en el punto 4.\nAsí, se podrá graficar el archivo de salida angles.xvg.\nDiedros\nPara el caso de los diedros la línea de comandos sería algo así:\ngmx gangle -f traj.xtc -n index -g1 dihedral -oav dihedrals.xvg -group1 “com of group W plus com of group X plus com of group Y plus com of group Z” -b A -e B\n-> Donde W, X, Y y Z son los grupos que se desee medir.\n-> Siendo A y B los mismos tiempos (en ps) utilizados en el punto 4.\nAsí, se podrá graficar el archivo de salida dihedrals.xvg.\nEstructura secundaria\nPara el cálculo de la estructura secundaria de la proteína en función del tiempo se necesitará realizar la instalación de un pequeño programa llamado dssp, el cual se puede hacer del siguiente sitio web: https://swift.cmbi.umcn.nl/gv/dssp. Además, Gromacs requiere que el ejecutable de dicho programa esté localizado en /usr/local/bin/dssp.\nLa siguiente línea de comando se utilizará para realizar este cálculo:\ngmx do_dssp -f traj.xtc -s coor-tpr.pdb -map ss.map -o ss.xpm -b A -e B\n-> Donde el archivo de entrada ss.map es aquel que mapea los datos de una matriz a valores RGB que son utilizados por el programa do_dssp. Este archivo debe contener lo siguiente:\n8\n\nCoil 1.0 1.0 1.0\nE B-Sheet 1.0 0.0 0.0\nB B-Bridge 0.0 0.0 0.0\nS Bend 0.0 0.8 0.8\nT Turn 1.0 1.0 0.0\nH A-Helix 0.0 0.0 1.0\nG 3-Helix 1.0 0.0 1.0\nI 5-Helix 1.0 0.6 0.0\n\nEl archivo de salida ss.xpm generado se podrá convertir a uno de imagen por el programa xpm2ps así:\ngmx xpm2ps -f ss.xpm -di ps.m2p -o ss.eps\n-> Donde el archivo de entrada ps.m2p es aquel que le da los parámetros (que se pueden modificar) al programa para generar el archivo de salida ss.eps. El archivo ps.m2p debe contener lo siguiente:\n; Command line options of xpm2ps override the parameters in this file\nblack&white = no ; Obsolete\ntitlefont = Times-Roman ; A PostScript Font\ntitlefontsize = 20 ; Font size (pt)\nlegend = yes ; Show the legend\nlegendfont = Times-Roman ; A PostScript Font\nlegendlabel = ; Used when there is none in the .xpm\nlegend2label = ; Used when merging two xpm’s\nlegendfontsize = 14 ; Font size (pt)\nxbox = 2.0 ; x-size of a matrix element\nybox = 2.0 ; y-size of a matrix element\nmatrixspacing = 20.0 ; Space between 2 matrices\nxoffset = 0.0 ; Between matrix and bounding box\nyoffset = 0.0 ; Between matrix and bounding box\nx-major = 20 ; Major ticks on x axis every .. frames\nx-minor = 5 ; Id. Minor ticks\nx-firstmajor = 0 ; First frame for major tick\nx-majorat0 = no ; Major tick at first frame\nx-majorticklen = 8.0 ; x-majorticklength\nx-minorticklen = 4.0 ; x-minorticklength\nx-label = ; Used when there is none in the .xpm\nx-fontsize = 16 ; Font size (pt)\nx-font = Times-Roman ; A PostScript Font\nx-tickfontsize = 10 ; Font size (pt)\nx-tickfont = Helvetica ; A PostScript Font\ny-major = 20\ny-minor = 5\ny-firstmajor = 0\ny-majorat0 = no\ny-majorticklen = 8.0\ny-minorticklen = 4.0\ny-label =\ny-fontsize = 16\ny-font = Times-Roman\ny-tickfontsize = 10\ny-tickfont = Helvetica\nDe esta manera, se generará el archivo de imagen ss.eps con las estructuras secundarias a color de la proteína a lo largo de la trayectoria (o intervalo escogido con las opciones -b A -e B en la primera línea de comandos).\nPara el caso del cálculo de las siguientes dos propiedades, densidad y enlaces de hidrógeno, se requerirá antes generar el archivo de entrada topol.tpr de la siguiente manera:\ngmx grompp -f grompp.mdp -s coor-tpr.pdb -p topol.top -o topol.tpr\n-> El archivo de entrada grompp.mdp, para este caso en particular, no requiere de datos específicos, por lo que bastará con que contenga las siguientes líneas:\n; grompp.mdp - used as input into grompp to generate topol.tpr\n; Parameters describing what to do, when to stop and what to save\nintegrator = steep ; Algorithm (steep = steepest descent minimization)\nemtol = 1000.0 ; Stop minimization when the maximum force < 1000.0 kJ/mol/nm\nemstep = 0.01 ; Minimization step size\nnsteps = 50000 ; Maximum number of (minimization) steps to perform\n; Parameters describing how to find the neighbors of each atom and how to calculate the interactions\nnstlist = 1 ; Frequency to update the neighbor list and long range forces\ncutoff-scheme = Verlet ; Buffered neighbor searching\nns_type = grid ; Method to determine neighbor list (simple, grid)\ncoulombtype = PME ; Treatment of long range electrostatic interactions\nrcoulomb = 1.0 ; Short-range electrostatic cut-off\nrvdw = 1.0 ; Short-range Van der Waals cut-off\npbc = xyz ; Periodic Boundary Conditions in all 3 dimensions\n-> Por otro lado, el archivo de entrada topol.top es indispensable y se podrá obtener por medio del servidor https://www.charmm-gui.org/ → “Input generator” → “Force Field Converter” utilizando los archivos de entrada *psf y *crd extraídos de la MD. Luego, se deberá marcar la opción “Gromacs” (al llegar al apartado “Input Generation Options”). Finalmente, luego de descargar los archivos generados comprimidos (*.tgz) y dentro de la carpeta “Gromacs” se encontrará el archivo de topología que requerimos.\nDe esta manera obtendremos el archivo topol.top necesario para los siguientes cálculos. Cabe mencionar que este archivo requiere también de los archivos generados de extensión itp que se encuentran dentro de la carpeta toppar.\nDensidad\nRespecto a este parámetro, a veces se requiere conocer la densidad de todo el sistema o de alguna de las partes del mismo (sobre todo en el caso de simulación de proteínas con membranas lipídicas), por lo que para tal motivo se utilizará la siguiente línea de comando:\ngmx density -f traj.xtc -s topol.tpr -o density.xvg -b A -e B\n-> Aquí utilizaremos el archivo de entrada recientemente generado topol.tpr\nEl resultado será el archivo de salida density.xvg el que contiene la información de la densidad a lo largo de la trayectoria escogida.\nEnlaces de hidrógeno\nSe podrá calcular la cantidad de enlaces como función del tiempo utilizando la siguiente línea de comando:\ngmx hbond -f traj.xtc -s topol.tpr -num hbnum.xvg -dist hbdist.xvg -ang hbang.xvg -dan danum.xvg -b A -e B\n-> Aquí utilizaremos el archivo de entrada recientemente generado topol.tpr\n-> El archivo de salida hbnum.xvg contendrá el número total de enlaces de hidrógeno por frame a lo largo de la trayectoria escogida.\n-> Los archivos de salida hbdist.xvg y hbang.xvg contendrán la distribución de la distancia y de los ángulos, respectivamente, para todos los enlaces de hidrógeno.\n-> El archivo de salida danum.xvg contendrá el número de dadores y aceptores analizados en cada frame de la trayectoria escogida.\nDe esta manera se podrán graficar los archivos xvg relacionados con el cálculo de los enlaces de hidrógeno.\nFinalmente, cabe mencionar que se puede utilizar el programa make_ndx para seleccionar diversos átomos, residuos o incluso una mezcla entre éstos y generar grupos que se guardarán en el archivo de salida index.ndx, el que se podrá utilizar en todos los análisis vistos en el presente tutorial, en el caso que así lo requiramos, adicionando a la línea de comandos lo siguiente: -n index.ndx.\n\n\n\nAbraham, Mark James, Teemu Murtola, Roland Schulz, Szilárd Páll, Jeremy C Smith, Berk Hess, and Erik Lindahl. 2015. “GROMACS: High Performance Molecular Simulations Through Multi-Level Parallelism from Laptops to Supercomputers.” SoftwareX 1: 19–25.\n\n\nPáll, Szilárd, Artem Zhmurov, Paul Bauer, Mark Abraham, Magnus Lundborg, Alan Gray, Berk Hess, and Erik Lindahl. 2020. “Heterogeneous Parallelization and Acceleration of Molecular Dynamics Simulations in GROMACS.” The Journal of Chemical Physics 153 (13): 134110.\n\n\n\n\n",
    "preview": "posts/tutorial_gromacs/pictures/gromacs.png",
    "last_modified": "2024-11-24T02:00:40-03:00",
    "input_file": {}
  }
]
